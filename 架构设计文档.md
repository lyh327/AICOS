# AICOS 架构设计文档

本文档面向开发与产品团队，描述项目主要模块、接口契约、数据结构、错误模式、测试策略与部署建议，便于后续维护和扩展。

## 1. 总体架构概览

AICOS 是一个基于 Next.js（App Router） + TypeScript 的前端与后端同构应用，主要模块包括：

- 前端页面与 UI 组件（Next.js 客户端组件）
- 后端 API 路由（Next.js API Route）
- 服务层（LLM、语音、会话存储等）
- 数据层（内置角色数据、会话/本地存储）

高层数据流：
用户（文本/语音）→ 前端 UI → 调用 `/api/chat` → `LLMService` （请求外部 GLM-4.5）→ 返回并持久化消息 → 前端渲染

## 2. 代码树（关键文件/目录）

- `src/app/chat/[id]/page.tsx` — 聊天主界面（客户端）
- `src/app/api/chat/route.ts` — 聊天后端 API 路由（Next Request/Response）
- `src/services/llm.ts` — GLM 调用封装（基础对话功能）
- `src/services/voice.ts` — ASR、TTS、语音相关封装
- `src/services/session-storage.ts` — 本地会话持久化（SessionStorage）
- `src/data/characters.ts` — 预设角色数据
- `src/types/index.ts` — 全局类型定义（Character、ChatMessage、ChatSession、LLMResponse 等）

## 3. 模块规格（接口 / 责任 / 数据契约）

下面按模块列出精确的契约（Inputs / Outputs / 错误模式 / 成功标准）。

### 3.1 `LLMService`（`src/services/llm.ts`）

职责：封装与外部 GLM-4.5 模型的交互。支持基础对话和继续生成功能。

主要公开方法：
- `generateResponse(character, userMessage, conversationHistory) -> Promise<LLMResponse>`
  - 基础对话功能，使用 GLM-4.5 模型
  - 成功返回：{ content, success: true, isComplete, finishReason }

- `continueResponse(character, previousContent, conversationHistory) -> Promise<LLMResponse>`
  - 用于继续生成被截断的回复

数据结构 - LLMResponse:
```ts
interface LLMResponse {
  content: string;
  success: boolean;
  error?: string;
  isComplete?: boolean; // 是否完整
  finishReason?: string; // 'stop'|'length'|'sensitive'|'tool_calls'
}
```

错误模式与降级：
- API 调用失败 -> 返回 `success: false` 与 `error` 文本；上层将使用 `getFallbackResponse` 生成降级回复
- 未返回 content -> 视为错误并走 fallback

成功标准：
- 正常返回内容并设置正确的完成状态。

### 3.2 API 路由 `/api/chat`（`src/app/api/chat/route.ts`）

职责：接收前端请求，做入参校验、速率限制、权限和反垃圾（若需要），调用 `LLMService` 返回结构化JSON。

输入 JSON：
```json
{
  characterId: string,
  character?: Character, // 可选自定义角色
  message?: string,
  conversationHistory?: { role: 'user'|'assistant', content: string }[],
  continueMessageId?: string,
  previousContent?: string
}
```

输出 JSON：
```json
{
  content, success, isComplete, finishReason, context?, character: { id,name,avatar }
}
```

错误与约束：
- 若缺少 `characterId` 或 `message`（且非 continue）返回 400
- 若角色不存在返回 404

### 3.3 `ChatPage`（`src/app/chat/[id]/page.tsx`）

职责：管理聊天 UI、会话创建、消息发送。

重要状态（局部 state）：
- `messages: ChatMessage[]`
- `currentSession: ChatSession | null`

消息数据结构 - `ChatMessage`（`src/types/index.ts`）:
```ts
interface ChatMessage {
  id: string;
  type: 'user'|'character';
  content: string;
  timestamp: Date;
  audioUrl?: string;
  isComplete?: boolean;
  canContinue?: boolean;
}
```

交互契约：
- 当发送消息时前端构造 `conversationHistory`（最近6轮）并 POST 到 `/api/chat`
- 前端显示对话处理状态

### 3.4 `SessionStorageService`（`src/services/session-storage.ts`）

职责：在浏览器端将会话保存在 local/session storage，提供 CRUD：
- `createSession(characterId, messages)`
- `addMessage(sessionId, message)`
- `getSession(sessionId)`
- `listSessions()`
- `removeSession(sessionId)`

导出功能（待实现/已提议）：
- 支持“按会话导出”：UI 列表允许选择一个或多个会话，导出为 JSON 或 Markdown。
- 导出契约包含会话元数据（id、characterId、title、createdAt）与消息数组（含 thinkingProcess、imageAnalysis）

### 3.5 `voice` 服务（`src/services/voice.ts`）

职责：封装 ASR/TTS（基于 Web Speech API 或后端服务）。

接口示例：
- `ASRService.startRecording(onResult, onEnd, onError, language)`
- `ASRService.stopRecording()`
- `TTSService.speak(text, options)`

错误模式：浏览器不支持 -> 返回 false，前端提示；网络 TTS 失败 -> 降级为本地 SpeechSynthesis（若可用）

## 4. 设计决策与说明

- 简化的对话模式：只保留基础对话功能，专注于核心的LLM对话体验。

- 错误与降级策略：
  - LLM API 出错：记录详细日志，返回人性化提示并使用预设 fallback 文本(已取消预设方案，因为会干扰到对于api调用的判断)
  - TTS/ASR 不可用：提供文本交互的备选方案

- 性能与安全：
  - 在后端实现简单的速率限制（API 路由已集成 rateLimit 检查）
  - 不在日志或前端暴露 API Key
  - 对用户输入进行长度限制（例如 10k 字符）以防止超量消耗

## 5. 测试计划（建议）

单元测试（服务层）
- `LLMService.generateStandardResponse`：测试基础对话功能和错误处理
- `session-storage`：增删改查操作、导出数据结构一致性

集成测试（端到端）
- 前端发送消息 -> `/api/chat` -> 返回回复并正确渲染

手动测试
- UI：测试基础对话功能
- 导出：选择会话导出为 JSON/MD（验证字段完备）

## 6. 导出会话功能（按会话导出）实现建议

需求： "会话导出应该分会话导出，且能选择会话"。

实现要点：
1. 在 `会话列表` 页面增加 `导出` 按钮（或批量导出入口），点击打开 `SessionExportDialog`。
2. `SessionExportDialog` 列出本地 `SessionStorageService.listSessions()`，每项显示 `title/character/createdAt/messageCount`，支持单选或多选。
3. 导出格式选项：`JSON`（原始结构）与 `Markdown`（人类可读）
4. 导出动作：构造导出数据 -> 调用浏览器 `Blob` + `URL.createObjectURL` -> 触发下载
5. 导出内容应该包含完整的消息结构。

导出数据结构示例（JSON）
```json
{
  "id": "session-...",
  "characterId": "harry-potter",
  "title": "与哈利的对话",
  "createdAt": "2025-09-23T...",
  "messages": [ { ... ChatMessage ... } ]
}
```

Markdown 导出示例格式：
```Markdown
# 会话标题 — 与哈利的对话
角色: 哈利·波特
创建时间: 2025-09-23

---

## 用户 (2025-09-23 10:00)
你好

## 哈利·波特 (2025-09-23 10:00)
你好！我是哈利·波特...

### 思考过程
> 我需要以哈利·波特的角色回应...

### 图像分析
> （如果有）...
```

## 7. 部署与监控

- 将前端/后端部署到 Vercel（Next.js 原生支持）或自托管 Node 服务
- 使用环境变量管理（`.env.local`），不要将密钥提交到仓库
- 在生产环境关闭 debug 日志；使用集中式日志/监控（Sentry/Datadog）监控 error/warn
- 为 LLM 请求统计消耗（tokens）、错误率、响应延时，便于成本控制