# AICOS 架构设计文档

本文档面向开发与产品团队，描述项目主要模块、接口契约、数据结构、错误模式、测试策略与部署建议，便于后续维护和扩展。

## 1. 总体架构概览

AICOS 是一个基于 Next.js（App Router） + TypeScript 的前端与后端同构应用，主要模块包括：

- 前端页面与 UI 组件（Next.js 客户端组件）
- 后端 API 路由（Next.js API Route）
- 服务层（LLM、语音、会话存储等）
- 数据层（内置角色数据、会话/本地存储）

高层数据流：
用户（文本/语音/图片）→ 前端 UI → 调用 `/api/chat` → `LLMService` （请求外部 GLM-4.5/GLM-4.5V）→ 返回并持久化消息 → 前端渲染（包含思考过程/图像分析等）

## 2. 代码树（关键文件/目录）

- `src/app/chat/[id]/page.tsx` — 聊天主界面（客户端）
- `src/app/api/chat/route.ts` — 聊天后端 API 路由（Next Request/Response）
- `src/services/llm.ts` — GLM 调用封装（包含 thinking/vision/continue 等）
- `src/services/voice.ts` — ASR、TTS、语音相关封装
- `src/services/session-storage.ts` — 本地会话持久化（SessionStorage）
- `src/components/ThinkingProcess.tsx` — 思考过程展示组件
- `src/components/ModeSelect.tsx` — 模式选择（已简化为深度思考开关）
- `src/data/characters.ts` — 预设角色数据
- `src/types/index.ts` — 全局类型定义（Character、ChatMessage、ChatSession、LLMResponse 等）

## 3. 模块规格（接口 / 责任 / 数据契约）

下面按模块列出精确的契约（Inputs / Outputs / 错误模式 / 成功标准）。

### 3.1 `LLMService`（`src/services/llm.ts`）

职责：封装与外部 GLM 系列模型的交互。支持三种主流程：标准模式、深度思考（thinking）、视觉理解（vision），以及继续生成（continue）。

主要公开方法：
- `generateResponse(character, userMessage, conversationHistory, options) -> Promise<LLMResponse>`
  - options: { enableThinking?: boolean; imageUrl?: string; mode?: 'standard'|'smart'|'thinking'|'vision' }
  - 根据 `mode` 路由到不同实现：thinking -> generateResponseWithThinking、vision -> generateResponseWithVision、smart -> generateSmartResponse、default -> generateStandardResponse

- `generateResponseWithThinking(character, userMessage, conversationHistory, enableThinking=false) -> Promise<LLMResponse>`
  - 请求体包含 `thinking: { type: 'enabled' }`（若 enableThinking）
  - 从响应中提取 `choices[0].message.content` 作为主回答
  - 从响应中提取思考过程字段（优先）`choice.message.reasoning_content`；兼容其它候选字段（think、thinking、thought_process 等）或 content 中嵌入的标记
  - 成功返回：{ content, success: true, isComplete, finishReason, thinkingProcess }

- `generateResponseWithVision(character, userMessage, imageUrl, conversationHistory) -> Promise<LLMResponse>`
  - 支持在 messages 中传递 image_url 类型内容，使用视觉模型 `glm-4.5v`
  - 返回包含 `imageAnalysis` 字段

- `continueResponse(character, previousContent, conversationHistory) -> Promise<LLMResponse>`
  - 用于继续生成被截断的回复

数据结构 - LLMResponse:
```ts
interface LLMResponse {
  content: string;
  success: boolean;
  error?: string;
  isComplete?: boolean; // 是否完整
  finishReason?: string; // 'stop'|'length'|'sensitive'|'tool_calls'
  thinkingProcess?: string; // 若启用思考并返回
  imageAnalysis?: string; // 若图像模式
}
```

错误模式与降级：
- API 调用失败 -> 返回 `success: false` 与 `error` 文本；上层将使用 `getFallbackResponse` 生成降级回复
- 未返回 content -> 视为错误并走 fallback
- 思考过程字段不存在 -> LLMService 中记录日志并允许降级（仍返回 content）

成功标准：
- 在 `enableThinking=true` 时，若后端返回 `reasoning_content` 或其它思考字段，应将其填入 `thinkingProcess` 并返回给前端。

### 3.2 API 路由 `/api/chat`（`src/app/api/chat/route.ts`）

职责：接收前端请求，做入参校验、速率限制、权限和反垃圾（若需要），调用 `LLMService` 返回结构化JSON。

输入 JSON：
```json
{
  characterId: string,
  character?: Character, // 可选自定义角色
  message?: string,
  conversationHistory?: { role: 'user'|'assistant', content: string }[],
  continueMessageId?: string,
  previousContent?: string,
  enableThinking?: boolean,
  imageUrl?: string,
  mode?: 'standard'|'smart'|'thinking'|'vision'
}
```

输出 JSON：
```json
{
  content, success, isComplete, finishReason, thinkingProcess?, imageAnalysis?, context?, character: { id,name,avatar }
}
```

错误与约束：
- 若缺少 `characterId` 或 `message`（且非 continue）返回 400
- 若角色不存在返回 404
- 对于有 `imageUrl` 的请求，应优先走 vision 分支；同时禁止同时启用 thinking（前端已禁用此场景）

### 3.3 `ChatPage`（`src/app/chat/[id]/page.tsx`）

职责：管理聊天 UI、会话创建、消息发送、文件上传、模式选择（深度思考开关）、展示思考过程和图像分析。

重要状态（局部 state）：
- `messages: ChatMessage[]`
- `currentSession: ChatSession | null`
- `enableThinking: boolean`（替代原来的 selectedMode）
- `selectedImage: string | null`

消息数据结构 - `ChatMessage`（`src/types/index.ts`）:
```ts
interface ChatMessage {
  id: string;
  type: 'user'|'character';
  content: string;
  timestamp: Date;
  audioUrl?: string;
  isComplete?: boolean;
  canContinue?: boolean;
  thinkingProcess?: string;
  imageAnalysis?: string;
  attachedImage?: string | null;
  mode?: 'standard'|'smart'|'thinking'|'vision';
}
```

交互契约：
- 当发送消息时前端构造 `conversationHistory`（最近6轮）并 POST 到 `/api/chat`，body 包含 `enableThinking: enableThinking` 与 `imageUrl`（若有）
- 前端根据后端返回的 `thinkingProcess` 字段渲染 `ThinkingProcess` 组件

前端约束：
- 若存在 `selectedImage`，应自动关闭 `enableThinking` 并禁用思考开关

### 3.4 `SessionStorageService`（`src/services/session-storage.ts`）

职责：在浏览器端将会话保存在 local/session storage，提供 CRUD：
- `createSession(characterId, messages)`
- `addMessage(sessionId, message)`
- `getSession(sessionId)`
- `listSessions()`
- `removeSession(sessionId)`

导出功能（待实现/已提议）：
- 支持“按会话导出”：UI 列表允许选择一个或多个会话，导出为 JSON 或 Markdown。
- 导出契约包含会话元数据（id、characterId、title、createdAt）与消息数组（含 thinkingProcess、imageAnalysis）

### 3.5 `voice` 服务（`src/services/voice.ts`）

职责：封装 ASR/TTS（基于 Web Speech API 或后端服务）。

接口示例：
- `ASRService.startRecording(onResult, onEnd, onError, language)`
- `ASRService.stopRecording()`
- `TTSService.speak(text, options)`

错误模式：浏览器不支持 -> 返回 false，前端提示；网络 TTS 失败 -> 降级为本地 SpeechSynthesis（若可用）

## 4. 设计决策与说明

- 深度思考（thinking）通过 `thinking.type` 参数启用；接收到的思考过程字段名在 GLM-4.5 上为 `reasoning_content`，因此解析逻辑以该字段为优先；为兼容性，代码同时尝试若干候选字段名，并在 content 中尝试解析特殊标记。

- 视觉理解和思考是互斥的：当上传图片时默认使用视觉模式（glm-4.5v），并禁用思考功能（前端与后端都应保证这一约束）。

- 错误与降级策略：
  - LLM API 出错：记录详细日志，返回人性化提示并使用预设 fallback 文本(已取消预设方案，因为会干扰到对于api调用的判断)
  - TTS/ASR 不可用：提供文本交互的备选方案

- 性能与安全：
  - 在后端实现简单的速率限制（API 路由已集成 rateLimit 检查）
  - 不在日志或前端暴露 API Key
  - 对用户输入进行长度限制（例如 10k 字符）以防止超量消耗

## 5. 测试计划（建议）

单元测试（服务层）
- `LLMService.generateResponseWithThinking`：模拟多种响应体（带 `reasoning_content`、不带思考字段、思考嵌入 content）并断言 `LLMResponse.thinkingProcess` 提取正确
- `LLMService.generateResponseWithVision`：模拟含 image analysis 的响应
- `session-storage`：增删改查操作、导出数据结构一致性

集成测试（端到端）
- 前端发送消息 -> `/api/chat` -> mock LLM 返回带 `reasoning_content`，前端应该渲染思考过程
- 上传图片后发送 -> 调用 vision 分支，返回 imageAnalysis 并渲染

手动测试
- UI：测试思考开关在有图片时被禁用并弹提示
- 导出：选择会话导出为 JSON/MD（验证字段完备）

## 6. 导出会话功能（按会话导出）实现建议

需求： "会话导出应该分会话导出，且能选择会话"。

实现要点：
1. 在 `会话列表` 页面增加 `导出` 按钮（或批量导出入口），点击打开 `SessionExportDialog`。
2. `SessionExportDialog` 列出本地 `SessionStorageService.listSessions()`，每项显示 `title/character/createdAt/messageCount`，支持单选或多选。
3. 导出格式选项：`JSON`（原始结构）与 `Markdown`（人类可读）
4. 导出动作：构造导出数据 -> 调用浏览器 `Blob` + `URL.createObjectURL` -> 触发下载
5. 导出内容应该包含每条消息的 `thinkingProcess` 与 `imageAnalysis` 字段。

导出数据结构示例（JSON）
```json
{
  "id": "session-...",
  "characterId": "harry-potter",
  "title": "与哈利的对话",
  "createdAt": "2025-09-23T...",
  "messages": [ { ... ChatMessage ... } ]
}
```

Markdown 导出示例格式：
```Markdown
# 会话标题 — 与哈利的对话
角色: 哈利·波特
创建时间: 2025-09-23

---

## 用户 (2025-09-23 10:00)
你好

## 哈利·波特 (2025-09-23 10:00)
你好！我是哈利·波特...

### 思考过程
> 我需要以哈利·波特的角色回应...

### 图像分析
> （如果有）...
```

## 7. 部署与监控

- 将前端/后端部署到 Vercel（Next.js 原生支持）或自托管 Node 服务
- 使用环境变量管理（`.env.local`），不要将密钥提交到仓库
- 在生产环境关闭 debug 日志；使用集中式日志/监控（Sentry/Datadog）监控 error/warn
- 为 LLM 请求统计消耗（tokens）、错误率、响应延时，便于成本控制